{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code requires about 10 minutes to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of preprocessing: **Data Cleaning**. Missing values handled by ignoring some tuples and using mean to fill in the remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1 = os.path.join('..','data','0_Final_Merged.csv')\n",
    "df = pd.read_csv(fp1)\n",
    "\n",
    "# All tuples that have 0 in the production column are removed\n",
    "df = df[np.isfinite(df['Production'])]\n",
    "\n",
    "# All nan values filled with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "states = list(df.State_Name.unique())\n",
    "years = list(df.Crop_Year.unique())\n",
    "months = list(df.Season.unique())\n",
    "for month in months:\n",
    "\tdf.loc[df['Season'] == month, 'Season'] = month.strip() # Removing trailing spaces\n",
    "months = list(df.Season.unique())\n",
    "\n",
    "# Filling nan values of rainfall with mean value for a particular state, year and month\n",
    "for state in states:\n",
    "\tfor year in years:\n",
    "\t\tfor month in months:\n",
    "\t\t\tsm = 0\n",
    "\t\t\tco = 0\n",
    "\t\t\tnew_df = df[(df['State_Name'] == state) & (df['Crop_Year'] == year) & (df['Season'] == month)]\n",
    "\t\t\tfor column in new_df['Rainfall']:\n",
    "\t\t\t\tif column != 0:\n",
    "\t\t\t\t\tsm += column\n",
    "\t\t\t\t\tco -= -1\n",
    "\t\t\tav = 0\n",
    "\t\t\tif co != 0: av = sm / co\n",
    "\t\t\tdf.loc[((df['State_Name'] == state) & (df['Crop_Year'] == year) & (df['Season'] == month) & (df['Rainfall'] == 0)), 'Rainfall'] = av\n",
    "\n",
    "count = 0\n",
    "summ = 0\n",
    "for i in df['Rainfall']:\n",
    "\tif i != 0:\n",
    "\t\tsumm += i\n",
    "\t\tcount -= -1\n",
    "\n",
    "avg = summ / count\n",
    "\n",
    "df.loc[(df['Rainfall'] == 0), 'Rainfall'] = avg\n",
    "\n",
    "# Storing the output of the first step of data preprocessing to csv file\n",
    "fp2 = os.path.join('..','data','1_Preprocess_Data_Cleaning.csv')\n",
    "df.to_csv(fp2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Reduction**: Stratified Sampling used for Numerosity Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp3 = os.path.join('..','data', '1_Preprocess_Data_Cleaning.csv')\n",
    "df = pd.read_csv(fp3)\n",
    "\n",
    "# Storing distinct column names\n",
    "column = list(df)\n",
    "\n",
    "# Creating a new dataframe that will be the output dataframe after nuerosity reduction\n",
    "my_df = pd.DataFrame(columns = column)\n",
    "\n",
    "# Storing unique Crop names\n",
    "crops = list(df.Crop.unique())\n",
    "\n",
    "# Stratified Sampling based on distinct crop names\n",
    "for crop in crops:\n",
    "\tnew_df = df[(df['Crop'] == crop)]\n",
    "\tnew_df = new_df.sample(frac = 0.7)\n",
    "\tmy_df = my_df.append(new_df, ignore_index = True)\n",
    "\n",
    "# Shuffling the dataframe to ensure randomness\n",
    "my_df = my_df.sample(frac = 1)\n",
    "\n",
    "# Storing the output in csv file\n",
    "fp4 = os.path.join('..','data', '2_Preprocess_Numerosity_Reduction.csv')\n",
    "my_df.to_csv(fp4, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp5 = os.path.join('..','data', '2_Preprocess_Numerosity_Reduction.csv')\n",
    "df = pd.read_csv(fp5)\n",
    "\n",
    "productions = []\n",
    "area = []\n",
    "\n",
    "for i in df['Production']: productions.append(i)\n",
    "\n",
    "for i in df['Area']: area.append(i)\n",
    "\n",
    "# Creating a new feature that will be used for all the further analysis\n",
    "yields = []\n",
    "\n",
    "for i in range(169655):\n",
    "\tyields.append(productions[i] / area[i])\n",
    "\n",
    "df['Yield'] = yields\n",
    "\n",
    "# Storing the output in csv file\n",
    "fp6 = os.path.join('..','data', '3_Preprocess_Feature_Construction.csv')\n",
    "df.to_csv(fp6, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**: Z-Score normalisation used to normalise 'Rainfall' and 'Yield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp7 = os.path.join('..','data', '3_Preprocess_Feature_Construction.csv')\n",
    "df = pd.read_csv(fp7)\n",
    "\n",
    "# Normalizing Rainfall using Z-Score\n",
    "rainfall_mean = df['Rainfall'].mean()\n",
    "rainfall_std = df['Rainfall'].std(ddof = 0)\n",
    "rainfall = []\n",
    "for i in df['Rainfall']: rainfall.append(i)\n",
    "for i in range(169655): rainfall[i] = (rainfall[i] - rainfall_mean) / rainfall_std\n",
    "df['Rainfall_ZScore'] = rainfall\n",
    "\n",
    "# Normalizing Yield using Z-Score\n",
    "yield_mean = df['Yield'].mean()\n",
    "yield_std = df['Yield'].std(ddof = 0)\n",
    "yields = []\n",
    "for i in df['Yield']: yields.append(i)\n",
    "for i in range(169655): yields[i] = (yields[i] - yield_mean) / yield_std\n",
    "df['Yield_ZScore'] = yields\n",
    "\n",
    "# Storing the output in csv file\n",
    "fp8 = os.path.join('..','data', '4_Preprocess_Normalization_Z_Score.csv')\n",
    "df.to_csv(fp8, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discretization**: 'Rainfall' and 'Yield' are discretized into five categories - _very low, low, medium, high, very_high_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp9 = os.path.join('..','data', '4_Preprocess_Normalization_Z_Score.csv')\n",
    "df = pd.read_csv(fp9)\n",
    "\n",
    "# Different categories for discretizing\n",
    "classes = ['Very_Low', 'Low', 'Medium', 'High', 'Very_High']\n",
    "\n",
    "# Discretizing Rainfall\n",
    "rainfall_z = []\n",
    "for i in df['Rainfall_ZScore']: rainfall_z.append(i)\n",
    "minrain = min(rainfall_z)\n",
    "maxrain = max(rainfall_z)\n",
    "count = [0] * 5\n",
    "for i in range(169655):\n",
    "\tif rainfall_z[i] < -1.22:\n",
    "\t\ttemp = 0\n",
    "\telif rainfall_z[i] < -0.5:\n",
    "\t\ttemp = 1\n",
    "\telif rainfall_z[i] < 0.5:\n",
    "\t\ttemp = 2\n",
    "\telif rainfall_z[i] < 2.5:\n",
    "\t\ttemp = 3\n",
    "\telse:\n",
    "\t\ttemp = 4\n",
    "\tcount[temp] -= -1\n",
    "\trainfall_z[i] = classes[temp]\n",
    "\n",
    "# Discretizing Yield\n",
    "yield_z = []\n",
    "for i in df['Yield_ZScore']: yield_z.append(i)\n",
    "minyield = min(yield_z)\n",
    "maxyield = max(yield_z)\n",
    "delta = (-0.047 - minyield) / 5\n",
    "count = [0] * 5\n",
    "for i in range(169655):\n",
    "\ttemp = int((yield_z[i] - minyield) // delta)\n",
    "\tif temp > 4: temp = 4\n",
    "\tcount[temp] -= -1\n",
    "\tyield_z[i] = classes[temp]\n",
    "\n",
    "df['Rainfall_Disc'] = rainfall_z\n",
    "df['Yield_Disc'] = yield_z\n",
    "\n",
    "# Storing the output in csv file\n",
    "fp10 = os.path.join('..','data', '5_Preprocess_Discretization.csv')\n",
    "df.to_csv(fp10, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binarization**: Discretized 'Rainfall' and 'Yield' are mapped to five binary variables corresponding to five categories. A binary variable represents the presence or absence of a record in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fp11 = os.path.join('..','data', '5_Preprocess_Discretization.csv')\n",
    "df = pd.read_csv(fp11)\n",
    "\n",
    "rainfall = []\n",
    "\n",
    "# Each bit represents a category for rainfall\n",
    "for i in df['Rainfall_Disc']:\n",
    "\tif i == 'Very_Low': rainfall.append([1, 0, 0, 0, 0])\n",
    "\telif i == 'Low': rainfall.append([0, 1, 0, 0, 0])\n",
    "\telif i == 'Medium': rainfall.append([0, 0, 1, 0, 0])\n",
    "\telif i == 'High': rainfall.append([0, 0, 0, 1, 0])\n",
    "\telse: rainfall.append([0, 0, 0, 0, 1])\n",
    "\n",
    "# Five categories of rainfall\n",
    "rainfall_vl = []\n",
    "rainfall_l = []\n",
    "rainfall_m = []\n",
    "rainfall_h = []\n",
    "rainfall_vh = []\n",
    "\n",
    "for i in range(169655):\n",
    "\trainfall_vl.append(rainfall[i][0])\n",
    "\trainfall_l.append(rainfall[i][1])\n",
    "\trainfall_m.append(rainfall[i][2])\n",
    "\trainfall_h.append(rainfall[i][3])\n",
    "\trainfall_vh.append(rainfall[i][4])\n",
    "\n",
    "df['Rainfall_Very_Low'] = rainfall_vl\n",
    "df['Rainfall_Low'] = rainfall_l\n",
    "df['Rainfall_Medium'] = rainfall_m\n",
    "df['Rainfall_High'] = rainfall_h\n",
    "df['Rainfall_Very_High'] = rainfall_vh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "yields = []\n",
    "\n",
    "# Each bit represents a category for yield\n",
    "for i in df['Yield_Disc']:\n",
    "\tif i == 'Very_Low': yields.append([1, 0, 0, 0, 0])\n",
    "\telif i == 'Low': yields.append([0, 1, 0, 0, 0])\n",
    "\telif i == 'Medium': yields.append([0, 0, 1, 0, 0])\n",
    "\telif i == 'High': yields.append([0, 0, 0, 1, 0])\n",
    "\telse: yields.append([0, 0, 0, 0, 1])\n",
    "\n",
    "# Five categories of yield\n",
    "yield_vl = []\n",
    "yield_l = []\n",
    "yield_m = []\n",
    "yield_h = []\n",
    "yield_vh = []\n",
    "\n",
    "for i in range(169655):\n",
    "\tyield_vl.append(yields[i][0])\n",
    "\tyield_l.append(yields[i][1])\n",
    "\tyield_m.append(yields[i][2])\n",
    "\tyield_h.append(yields[i][3])\n",
    "\tyield_vh.append(yields[i][4])\n",
    "\n",
    "df['Yield_Very_Low'] = yield_vl\n",
    "df['Yield_Low'] = yield_l\n",
    "df['Yield_Medium'] = yield_m\n",
    "df['Yield_High'] = yield_h\n",
    "df['Yield_Very_High'] = yield_vh\n",
    "\n",
    "# Storing the output in csv file\n",
    "fp12 = os.path.join('..','data' , '6_Preprocess_Binarization.csv')\n",
    "df.to_csv(fp12, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Preprocessed Data**: All the columns that are not important for our further analysis (Association Rule Mining, Clustering and Classification) are now removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['State_Name', 'District_Name', 'Crop_Year', 'Area', 'Production', 'Rainfall', 'Yield', 'Rainfall_ZScore', 'Yield_ZScore'], axis = 1)\n",
    "fp13 = os.path.join('..','data', '7_Preprocess_Final.csv')\n",
    "df.to_csv(fp13, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
